{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Install necessary libraries\n",
    "# !pip install -q datasets trl bitsandbytes sentencepiece\n",
    "# !pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "# # Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritwik21557/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import gc\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel, get_peft_model, prepare_model_for_kbit_training, AutoPeftModelForCausalLM\n",
    "from trl import DPOTrainer, DPOConfig\n",
    "import bitsandbytes as bnb\n",
    "from datasets import load_from_disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model names and tokens\n",
    "peft_model_name = \"Ronal999/phi2_finance_SFT\" # The model obtained after the SFT step\n",
    "new_model = \"phi2_DPO\" #the name of the DPO trained model\n",
    "\n",
    "# Tokenizer setup\n",
    "tokenizer = AutoTokenizer.from_pretrained(peft_model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.chat_template = \"chat_template_function\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': 'chat_template_function', 'chosen': '{\"person_details\": {\"phone\": \"+91 7374091655\", \"email\": \"rk220217@gmail.com\", \"github\": \"rohan220217\", \"linkedin\": \"rohan-kumar-a65a87175/\", \"name\": \"Rohan Kumar\"}, \"education\": {\"B.Tech + M.Tech in Computer Science\": {\"university\": \"Jawaharlal Nehru University\", \"duration\": \"2018 \\\\u2014 2023\", \"cgpa\": \"6.9/ 9.0\"}, \"Higher Secondary\": {\"school\": \"Satyadeo College (BSEB Board)\", \"duration\": \"2016 \\\\u2014 2018\", \"percentage\": \"73.4%\"}, \"Secondary\": {\"school\": \"RamaKrishna Mission Vidya Mandir (CBSE Board)\", \"duration\": \"2015 \\\\u2014 2016\", \"cgpa\": \"9.6/ 10\"}}, \"skills\": {\"Languages\": [\"C++\", \"Javascript\", \"Python\", \"Dart\"], \"Frontend Development\": [\"Html\", \"Css\", \"Sass\", \"Tailwind\", \"Bootstrap\", \"Vuejs\", \"Reactjs\", \"Redux\", \"Vuetify\", \"QT\"], \"Backend Development\": [\"NodeJs\", \"ExpressJs\", \"Django\", \"Flask\"], \"App Development\": [\"Flutter\", \"Vue Native\", \"Nativescript Vue\"], \"Tools\": [\"NuxtJs\", \"Postman\", \"Git\", \"Canva\", \"Figma\", \"Vim\"]}, \"work_ex\": {\"KOWI PVT .L TD.\": {\"duration\": \"JUL 2021 \\\\u2014 OCT 2021\", \"role\": \"Frontend Developer\"}, \"IIT Bombay\": {\"duration\": \"OCT 2021\", \"role\": \"Mobile App Developer\"}, \"Ringover France\": {\"duration\": \"JUN 2022 \\\\u2014 SEP 2022\", \"role\": \"ReactJS and Socket Developer\"}}, \"projects\": {\"Personal Portfolio\": {\"duration\": \"FEB 2022 \\\\u2014 MAR 2022\", \"tech_stack\": [\"ReactJS\", \"Css\"]}, \"Kyron Landing Page\": {\"duration\": \"MAR 2022 \\\\u2014 APR 2022\", \"tech_stack\": [\"ReactJS\", \"Sass\"]}, \"Employee Management System\": {\"duration\": \"JUl 2021 \\\\u2014 OCT 2021\", \"tech_stack\": [\"VueJS\", \"Vuetify\"]}, \"AnyaGreen Admin Panel\": {\"duration\": \"NOV 2020 \\\\u2014 APR 2021\", \"tech_stack\": [\"VueJS\", \"Vuetify\"]}, \"AnyaGreen Android App\": {\"duration\": \"NOV 2020 \\\\u2014 APR 2021\", \"tech_stack\": [\"Flutter\"]}, \"Teachomatrix\": {\"duration\": \"JUL 2020 \\\\u2014 NA\", \"tech_stack\": [\"VueJS\", \"Vuetify\"]}, \"Open Source Internship\": {\"duration\": \"MAY 2021 \\\\u2014 NA\", \"tech_stack\": [\"VueJS\", \"Vuetify\"]}, \"Ornate\": {\"duration\": \"MAR 2021 \\\\u2014 NA\", \"tech_stack\": [\"VueJS\", \"Bootstrap\"]}, \"access2successonline\": {\"duration\": \"OCT 2021\", \"tech_stack\": [\"VueJS\", \"Vuetify\"]}, \"VenaIndia\": {\"duration\": \"DEC 2019 \\\\u2014 FEB 2020\", \"tech_stack\": [\"Html\", \"Css\", \"Bootstrap\", \"JS\"]}, \"Periplo\": {\"duration\": \"NOV 2019 \\\\u2014 DEC 2019\", \"tech_stack\": [\"Html\", \"Css\", \"Bootstrap\", \"JS\"]}, \"HackJNU\": {\"duration\": \"NA\", \"tech_stack\": [\"Html\", \"Css\", \"Bootstrap\", \"JS\"]}}, \"extras\": {\"activities\": [\"Created a landing page and registration form for Adobe Shecodes\", \"Completed my 3 month internship and got the PPO from Ringover\", \"Successfully completed my 3 month internship at KOWI.PVT .L TD as Mobile and Web Developer\", \"Won my first Hackathon (SIT Karnataka) Dynamic Hack 2021\", \"Deploy my first android app on Playstore Anya Green\", \"Administrative Executive at LooP The Developer\\\\u2019s Club\", \"Contributed to Open Source Vuetify\", \"Organizer of HackJNU and HackJNU 2.0\"]}}\\n', 'rejected': '{\"person_details\": {\"name\": \"Bhawna Anand\", \"contact\": \"9899001728\", \"email\": \"bhavuanand1201@gmail.com\", \"linkedin\": \"https://www.linkedin.com/in/bhawna-anand-88030a219/\", \"github\": \"https://github.com/BhavuAnand?tab=repositories\"}, \"education\": {\"school\": \"ST. MICHAEL\\\\u2019S SR. SEC. SCHOOL\", \"school_percentage\": {\"class_x\": \"88.4%\", \"class_xii\": \"80%\"}, \"university\": \"INDIRA GANDHI DELHI TECHNICAL UNIVERSITY FOR WOMEN\", \"degree\": \"B.Tech, IT\", \"cgpa\": \"8.04\"}, \"skills\": {\"programming_languages\": {\"beginner\": [\"Python\", \"C\"], \"intermediate\": [\"Java\", \"C++\"]}, \"other_skills\": {\"beginner\": [\"Web Development\", \"HTML\", \"Data Analytics\"], \"intermediate\": [\"Data Structures\", \"SQL\", \"Problem Solving and Logic Building\"]}, \"soft_skills\": [\"Leadership\", \"Public Relations\", \"Active Listener\", \"Teamwork\", \"Time Management\"]}, \"work_ex\": {\"position\": \"MEMBER OF EVENT MANAGEMENT TEAM OF COLLEGE ANNUAL FEST\", \"description\": \"Managed and organized events with full responsibilities in the college of the annual fest.\"}, \"projects\": {\"bank_management_system\": {\"description\": \"This project, coded in C Language, consists of basic operations that are done by a bank.\", \"github_link\": \"https://github.com/BhavuAnand/bank_management/blob/main/bank_system.c\"}, \"recommendation_system_engine\": {\"description\": \"Recommendation engine which recommends generic medicines according to the searches for a particular product.\", \"github_link\": \"https://github.com/BhavuAnand/microsoft-recommendation\"}}, \"extras\": {\"achievements\": [\"MICROSOFT ENGAGE\"], \"languages\": [\"English\", \"Hindi\", \"Japanese\"]}}\\n'}\n"
     ]
    }
   ],
   "source": [
    "def chatml_format(example):\n",
    "\n",
    "    # Formatting user instruction\n",
    "    message = {\"role\": \"user\", \"content\": example['input']}\n",
    "    prompt = tokenizer.apply_chat_template([message], tokenize=False, add_generation_prompt=True)\n",
    "\n",
    "    # Formatting the chosen answer\n",
    "    chosen = example['preferred'] + \"\\n\"\n",
    "\n",
    "    # Formatting the rejected answer\n",
    "    rejected = example['dispreferred'] + \"\\n\"\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompt,\n",
    "        \"chosen\": chosen,\n",
    "        \"rejected\": rejected,\n",
    "    }\n",
    "\n",
    "# Loading the dataset\n",
    "dataset = load_from_disk(\"dataset\")\n",
    "# Saving original columns for removal\n",
    "original_columns = dataset.column_names\n",
    "\n",
    "# Applying formatting to the dataset\n",
    "dataset = dataset.map(\n",
    "    chatml_format,\n",
    "    remove_columns=original_columns\n",
    ")\n",
    "\n",
    "# Displaying a sample from the dataset\n",
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['base_model.model.model.embed_tokens.weight', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.0.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.0.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.0.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.0.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.0.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.0.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.0.mlp.fc1.weight', 'base_model.model.model.layers.0.mlp.fc1.bias', 'base_model.model.model.layers.0.mlp.fc2.weight', 'base_model.model.model.layers.0.mlp.fc2.bias', 'base_model.model.model.layers.0.input_layernorm.weight', 'base_model.model.model.layers.0.input_layernorm.bias', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.1.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.1.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.1.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.1.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.1.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.1.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.1.mlp.fc1.weight', 'base_model.model.model.layers.1.mlp.fc1.bias', 'base_model.model.model.layers.1.mlp.fc2.weight', 'base_model.model.model.layers.1.mlp.fc2.bias', 'base_model.model.model.layers.1.input_layernorm.weight', 'base_model.model.model.layers.1.input_layernorm.bias', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.2.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.2.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.2.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.2.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.2.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.2.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.2.mlp.fc1.weight', 'base_model.model.model.layers.2.mlp.fc1.bias', 'base_model.model.model.layers.2.mlp.fc2.weight', 'base_model.model.model.layers.2.mlp.fc2.bias', 'base_model.model.model.layers.2.input_layernorm.weight', 'base_model.model.model.layers.2.input_layernorm.bias', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.3.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.3.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.3.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.3.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.3.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.3.mlp.fc1.weight', 'base_model.model.model.layers.3.mlp.fc1.bias', 'base_model.model.model.layers.3.mlp.fc2.weight', 'base_model.model.model.layers.3.mlp.fc2.bias', 'base_model.model.model.layers.3.input_layernorm.weight', 'base_model.model.model.layers.3.input_layernorm.bias', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.4.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.4.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.4.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.4.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.4.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.4.mlp.fc1.weight', 'base_model.model.model.layers.4.mlp.fc1.bias', 'base_model.model.model.layers.4.mlp.fc2.weight', 'base_model.model.model.layers.4.mlp.fc2.bias', 'base_model.model.model.layers.4.input_layernorm.weight', 'base_model.model.model.layers.4.input_layernorm.bias', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.5.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.5.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.5.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.5.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.5.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.5.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.5.mlp.fc1.weight', 'base_model.model.model.layers.5.mlp.fc1.bias', 'base_model.model.model.layers.5.mlp.fc2.weight', 'base_model.model.model.layers.5.mlp.fc2.bias', 'base_model.model.model.layers.5.input_layernorm.weight', 'base_model.model.model.layers.5.input_layernorm.bias', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.6.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.6.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.6.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.6.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.6.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.6.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.6.mlp.fc1.weight', 'base_model.model.model.layers.6.mlp.fc1.bias', 'base_model.model.model.layers.6.mlp.fc2.weight', 'base_model.model.model.layers.6.mlp.fc2.bias', 'base_model.model.model.layers.6.input_layernorm.weight', 'base_model.model.model.layers.6.input_layernorm.bias', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.7.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.7.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.7.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.7.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.7.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.7.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.7.mlp.fc1.weight', 'base_model.model.model.layers.7.mlp.fc1.bias', 'base_model.model.model.layers.7.mlp.fc2.weight', 'base_model.model.model.layers.7.mlp.fc2.bias', 'base_model.model.model.layers.7.input_layernorm.weight', 'base_model.model.model.layers.7.input_layernorm.bias', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.8.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.8.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.8.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.8.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.8.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.8.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.8.mlp.fc1.weight', 'base_model.model.model.layers.8.mlp.fc1.bias', 'base_model.model.model.layers.8.mlp.fc2.weight', 'base_model.model.model.layers.8.mlp.fc2.bias', 'base_model.model.model.layers.8.input_layernorm.weight', 'base_model.model.model.layers.8.input_layernorm.bias', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.9.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.9.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.9.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.9.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.9.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.9.mlp.fc1.weight', 'base_model.model.model.layers.9.mlp.fc1.bias', 'base_model.model.model.layers.9.mlp.fc2.weight', 'base_model.model.model.layers.9.mlp.fc2.bias', 'base_model.model.model.layers.9.input_layernorm.weight', 'base_model.model.model.layers.9.input_layernorm.bias', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.10.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.10.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.10.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.10.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.10.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.10.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.10.mlp.fc1.weight', 'base_model.model.model.layers.10.mlp.fc1.bias', 'base_model.model.model.layers.10.mlp.fc2.weight', 'base_model.model.model.layers.10.mlp.fc2.bias', 'base_model.model.model.layers.10.input_layernorm.weight', 'base_model.model.model.layers.10.input_layernorm.bias', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.11.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.11.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.11.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.11.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.11.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.11.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.11.mlp.fc1.weight', 'base_model.model.model.layers.11.mlp.fc1.bias', 'base_model.model.model.layers.11.mlp.fc2.weight', 'base_model.model.model.layers.11.mlp.fc2.bias', 'base_model.model.model.layers.11.input_layernorm.weight', 'base_model.model.model.layers.11.input_layernorm.bias', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.12.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.12.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.12.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.12.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.12.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.12.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.12.mlp.fc1.weight', 'base_model.model.model.layers.12.mlp.fc1.bias', 'base_model.model.model.layers.12.mlp.fc2.weight', 'base_model.model.model.layers.12.mlp.fc2.bias', 'base_model.model.model.layers.12.input_layernorm.weight', 'base_model.model.model.layers.12.input_layernorm.bias', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.13.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.13.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.13.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.13.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.13.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.13.mlp.fc1.weight', 'base_model.model.model.layers.13.mlp.fc1.bias', 'base_model.model.model.layers.13.mlp.fc2.weight', 'base_model.model.model.layers.13.mlp.fc2.bias', 'base_model.model.model.layers.13.input_layernorm.weight', 'base_model.model.model.layers.13.input_layernorm.bias', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.14.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.14.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.14.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.14.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.14.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.14.mlp.fc1.weight', 'base_model.model.model.layers.14.mlp.fc1.bias', 'base_model.model.model.layers.14.mlp.fc2.weight', 'base_model.model.model.layers.14.mlp.fc2.bias', 'base_model.model.model.layers.14.input_layernorm.weight', 'base_model.model.model.layers.14.input_layernorm.bias', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.15.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.15.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.15.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.15.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.15.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.15.mlp.fc1.weight', 'base_model.model.model.layers.15.mlp.fc1.bias', 'base_model.model.model.layers.15.mlp.fc2.weight', 'base_model.model.model.layers.15.mlp.fc2.bias', 'base_model.model.model.layers.15.input_layernorm.weight', 'base_model.model.model.layers.15.input_layernorm.bias', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.16.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.16.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.16.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.16.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.16.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.16.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.16.mlp.fc1.weight', 'base_model.model.model.layers.16.mlp.fc1.bias', 'base_model.model.model.layers.16.mlp.fc2.weight', 'base_model.model.model.layers.16.mlp.fc2.bias', 'base_model.model.model.layers.16.input_layernorm.weight', 'base_model.model.model.layers.16.input_layernorm.bias', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.17.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.17.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.17.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.17.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.17.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.17.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.17.mlp.fc1.weight', 'base_model.model.model.layers.17.mlp.fc1.bias', 'base_model.model.model.layers.17.mlp.fc2.weight', 'base_model.model.model.layers.17.mlp.fc2.bias', 'base_model.model.model.layers.17.input_layernorm.weight', 'base_model.model.model.layers.17.input_layernorm.bias', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.18.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.18.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.18.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.18.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.18.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.18.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.18.mlp.fc1.weight', 'base_model.model.model.layers.18.mlp.fc1.bias', 'base_model.model.model.layers.18.mlp.fc2.weight', 'base_model.model.model.layers.18.mlp.fc2.bias', 'base_model.model.model.layers.18.input_layernorm.weight', 'base_model.model.model.layers.18.input_layernorm.bias', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.19.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.19.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.19.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.19.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.19.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.19.mlp.fc1.weight', 'base_model.model.model.layers.19.mlp.fc1.bias', 'base_model.model.model.layers.19.mlp.fc2.weight', 'base_model.model.model.layers.19.mlp.fc2.bias', 'base_model.model.model.layers.19.input_layernorm.weight', 'base_model.model.model.layers.19.input_layernorm.bias', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.20.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.20.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.20.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.20.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.20.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.20.mlp.fc1.weight', 'base_model.model.model.layers.20.mlp.fc1.bias', 'base_model.model.model.layers.20.mlp.fc2.weight', 'base_model.model.model.layers.20.mlp.fc2.bias', 'base_model.model.model.layers.20.input_layernorm.weight', 'base_model.model.model.layers.20.input_layernorm.bias', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.21.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.21.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.21.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.21.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.21.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.21.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.21.mlp.fc1.weight', 'base_model.model.model.layers.21.mlp.fc1.bias', 'base_model.model.model.layers.21.mlp.fc2.weight', 'base_model.model.model.layers.21.mlp.fc2.bias', 'base_model.model.model.layers.21.input_layernorm.weight', 'base_model.model.model.layers.21.input_layernorm.bias', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.22.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.22.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.22.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.22.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.22.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.22.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.22.mlp.fc1.weight', 'base_model.model.model.layers.22.mlp.fc1.bias', 'base_model.model.model.layers.22.mlp.fc2.weight', 'base_model.model.model.layers.22.mlp.fc2.bias', 'base_model.model.model.layers.22.input_layernorm.weight', 'base_model.model.model.layers.22.input_layernorm.bias', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.23.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.23.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.23.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.23.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.23.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.23.mlp.fc1.weight', 'base_model.model.model.layers.23.mlp.fc1.bias', 'base_model.model.model.layers.23.mlp.fc2.weight', 'base_model.model.model.layers.23.mlp.fc2.bias', 'base_model.model.model.layers.23.input_layernorm.weight', 'base_model.model.model.layers.23.input_layernorm.bias', 'base_model.model.model.layers.24.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.24.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.24.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.24.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.24.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.24.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.24.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.24.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.24.mlp.fc1.weight', 'base_model.model.model.layers.24.mlp.fc1.bias', 'base_model.model.model.layers.24.mlp.fc2.weight', 'base_model.model.model.layers.24.mlp.fc2.bias', 'base_model.model.model.layers.24.input_layernorm.weight', 'base_model.model.model.layers.24.input_layernorm.bias', 'base_model.model.model.layers.25.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.25.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.25.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.25.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.25.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.25.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.25.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.25.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.25.mlp.fc1.weight', 'base_model.model.model.layers.25.mlp.fc1.bias', 'base_model.model.model.layers.25.mlp.fc2.weight', 'base_model.model.model.layers.25.mlp.fc2.bias', 'base_model.model.model.layers.25.input_layernorm.weight', 'base_model.model.model.layers.25.input_layernorm.bias', 'base_model.model.model.layers.26.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.26.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.26.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.26.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.26.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.26.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.26.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.26.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.26.mlp.fc1.weight', 'base_model.model.model.layers.26.mlp.fc1.bias', 'base_model.model.model.layers.26.mlp.fc2.weight', 'base_model.model.model.layers.26.mlp.fc2.bias', 'base_model.model.model.layers.26.input_layernorm.weight', 'base_model.model.model.layers.26.input_layernorm.bias', 'base_model.model.model.layers.27.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.27.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.27.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.27.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.27.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.27.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.27.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.27.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.27.mlp.fc1.weight', 'base_model.model.model.layers.27.mlp.fc1.bias', 'base_model.model.model.layers.27.mlp.fc2.weight', 'base_model.model.model.layers.27.mlp.fc2.bias', 'base_model.model.model.layers.27.input_layernorm.weight', 'base_model.model.model.layers.27.input_layernorm.bias', 'base_model.model.model.layers.28.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.28.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.28.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.28.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.28.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.28.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.28.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.28.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.28.mlp.fc1.weight', 'base_model.model.model.layers.28.mlp.fc1.bias', 'base_model.model.model.layers.28.mlp.fc2.weight', 'base_model.model.model.layers.28.mlp.fc2.bias', 'base_model.model.model.layers.28.input_layernorm.weight', 'base_model.model.model.layers.28.input_layernorm.bias', 'base_model.model.model.layers.29.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.29.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.29.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.29.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.29.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.29.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.29.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.29.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.29.mlp.fc1.weight', 'base_model.model.model.layers.29.mlp.fc1.bias', 'base_model.model.model.layers.29.mlp.fc2.weight', 'base_model.model.model.layers.29.mlp.fc2.bias', 'base_model.model.model.layers.29.input_layernorm.weight', 'base_model.model.model.layers.29.input_layernorm.bias', 'base_model.model.model.layers.30.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.30.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.30.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.30.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.30.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.30.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.30.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.30.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.30.mlp.fc1.weight', 'base_model.model.model.layers.30.mlp.fc1.bias', 'base_model.model.model.layers.30.mlp.fc2.weight', 'base_model.model.model.layers.30.mlp.fc2.bias', 'base_model.model.model.layers.30.input_layernorm.weight', 'base_model.model.model.layers.30.input_layernorm.bias', 'base_model.model.model.layers.31.self_attn.q_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.q_proj.base_layer.bias', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.training2.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.training2.weight', 'base_model.model.model.layers.31.self_attn.k_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.k_proj.base_layer.bias', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.training2.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.training2.weight', 'base_model.model.model.layers.31.self_attn.v_proj.base_layer.weight', 'base_model.model.model.layers.31.self_attn.v_proj.base_layer.bias', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.training2.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.training2.weight', 'base_model.model.model.layers.31.self_attn.dense.base_layer.weight', 'base_model.model.model.layers.31.self_attn.dense.base_layer.bias', 'base_model.model.model.layers.31.self_attn.dense.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.dense.lora_A.training2.weight', 'base_model.model.model.layers.31.self_attn.dense.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.dense.lora_B.training2.weight', 'base_model.model.model.layers.31.mlp.fc1.weight', 'base_model.model.model.layers.31.mlp.fc1.bias', 'base_model.model.model.layers.31.mlp.fc2.weight', 'base_model.model.model.layers.31.mlp.fc2.bias', 'base_model.model.model.layers.31.input_layernorm.weight', 'base_model.model.model.layers.31.input_layernorm.bias', 'base_model.model.model.final_layernorm.weight', 'base_model.model.model.final_layernorm.bias', 'base_model.model.lm_head.weight', 'base_model.model.lm_head.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=['k_proj', 'v_proj', 'q_proj', 'dense']\n",
    ")\n",
    "\n",
    "# Load the base model with BitsAndBytes configuration\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_has_fp16_weight=False,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    peft_model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    quantization_config=bnb_config,\n",
    "    is_trainable=True,\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "model.load_adapter(peft_model_name, adapter_name=\"training2\")\n",
    "model.load_adapter(peft_model_name, adapter_name=\"reference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting prompt from train dataset:   0%|          | 0/170 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting prompt from train dataset: 100%|██████████| 170/170 [00:00<00:00, 2604.82 examples/s]\n",
      "Applying chat template to train dataset: 100%|██████████| 170/170 [00:00<00:00, 5650.60 examples/s]\n",
      "Tokenizing train dataset: 100%|██████████| 170/170 [00:00<00:00, 174.62 examples/s]\n",
      "Detected kernel version 4.15.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Initialize Training arguments\n",
    "training_args = DPOConfig(output_dir=\"checkpoints\", logging_steps=10)\n",
    "\n",
    "# Initialize DPO Trainer\n",
    "dpo_trainer = DPOTrainer(model=model, args=training_args , processing_class = tokenizer,train_dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 62135/62135 [00:01<00:00, 43777.76 examples/s]\n",
      "Generating test split: 100%|██████████| 1000/1000 [00:00<00:00, 38992.12 examples/s]\n",
      "Extracting prompt from train dataset: 100%|██████████| 62135/62135 [00:19<00:00, 3150.41 examples/s]\n",
      "Applying chat template to train dataset:  60%|██████    | 37440/62135 [00:32<00:21, 1141.51 examples/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m load_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrl-lib/ultrafeedback_binarized\u001b[39m\u001b[38;5;124m\"\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m training_args \u001b[38;5;241m=\u001b[39m DPOConfig(output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQwen2-0.5B-DPO\u001b[39m\u001b[38;5;124m\"\u001b[39m, logging_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mDPOTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m         message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m custom_message\n\u001b[1;32m    100\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/transformers/utils/deprecation.py:165\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action\u001b[38;5;241m.\u001b[39mNOTIFY, Action\u001b[38;5;241m.\u001b[39mNOTIFY_ALWAYS):\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 165\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/trl/trainer/dpo_trainer.py:599\u001b[0m, in \u001b[0;36mDPOTrainer.__init__\u001b[0;34m(self, model, ref_model, beta, label_smoothing, loss_type, args, data_collator, label_pad_token_id, padding_value, truncation_mode, train_dataset, eval_dataset, processing_class, model_init, callbacks, optimizers, preprocess_logits_for_metrics, max_length, max_prompt_length, max_target_length, peft_config, is_encoder_decoder, disable_dropout, generate_during_eval, compute_metrics, precompute_ref_log_probs, dataset_num_proc, model_init_kwargs, ref_model_init_kwargs, model_adapter_name, ref_adapter_name, reference_free, force_use_ref_model)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m PartialState()\u001b[38;5;241m.\u001b[39mlocal_main_process_first():\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;66;03m# Extract the prompt if needed, and apply the chat template if needed\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    597\u001b[0m         maybe_extract_prompt, num_proc\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdataset_num_proc, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting prompt from train dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    598\u001b[0m     )\n\u001b[0;32m--> 599\u001b[0m     train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaybe_apply_chat_template\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtokenizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessing_class\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset_num_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mApplying chat template to train dataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    606\u001b[0m         eval_dataset \u001b[38;5;241m=\u001b[39m eval_dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    607\u001b[0m             maybe_extract_prompt, num_proc\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdataset_num_proc, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracting prompt from eval dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    608\u001b[0m         )\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/datasets/arrow_dataset.py:560\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    553\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    558\u001b[0m }\n\u001b[1;32m    559\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 560\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    562\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/datasets/arrow_dataset.py:3035\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3029\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3030\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3031\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3032\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3033\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3034\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3035\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3036\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3037\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/datasets/arrow_dataset.py:3408\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3406\u001b[0m _time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3407\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, example \u001b[38;5;129;01min\u001b[39;00m shard_iterable:\n\u001b[0;32m-> 3408\u001b[0m     example \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3409\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m update_data:\n\u001b[1;32m   3410\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/datasets/arrow_dataset.py:3300\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3299\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3300\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3302\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3303\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3304\u001b[0m     }\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/trl/data_utils.py:185\u001b[0m, in \u001b[0;36mmaybe_apply_chat_template\u001b[0;34m(example, tokenizer)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmaybe_apply_chat_template\u001b[39m(\n\u001b[1;32m    142\u001b[0m     example: Dict[\u001b[38;5;28mstr\u001b[39m, List[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]]], tokenizer: PreTrainedTokenizer\n\u001b[1;32m    143\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03m    If the example is in a conversational format, apply a chat template to it.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_conversational\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexample\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m apply_chat_template(example, tokenizer)\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/trl/data_utils.py:52\u001b[0m, in \u001b[0;36mis_conversational\u001b[0;34m(example)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m example_keys:\n\u001b[1;32m     51\u001b[0m     key \u001b[38;5;241m=\u001b[39m example_keys\u001b[38;5;241m.\u001b[39mpop()  \u001b[38;5;66;03m# take the first supported key\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m     maybe_messages \u001b[38;5;241m=\u001b[39m \u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m# It must be a list of messages,\u001b[39;00m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(maybe_messages, \u001b[38;5;28mlist\u001b[39m):\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/datasets/formatting/formatting.py:279\u001b[0m, in \u001b[0;36mLazyDict.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    277\u001b[0m value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key]\n\u001b[1;32m    278\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format:\n\u001b[0;32m--> 279\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[key] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeys_to_format\u001b[38;5;241m.\u001b[39mremove(key)\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/datasets/formatting/formatting.py:377\u001b[0m, in \u001b[0;36mLazyRow.format\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_column\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/datasets/formatting/formatting.py:448\u001b[0m, in \u001b[0;36mPythonFormatter.format_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 448\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_arrow_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    449\u001b[0m     column \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_column(column, pa_table\u001b[38;5;241m.\u001b[39mcolumn_names[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column\n",
      "File \u001b[0;32m~/IP_NOVEL_RECIPE/env/lib/python3.12/site-packages/datasets/formatting/formatting.py:148\u001b[0m, in \u001b[0;36mPythonArrowExtractor.extract_column\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa_table\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_pylist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start Fine-tuning with DPO\n",
    "dpo_trainer.train()\n",
    "\n",
    "# Saving the fine-tuned model and tokenizer\n",
    "dpo_trainer.model.save_pretrained(\"saved_model/model\")\n",
    "tokenizer.save_pretrained(\"saved_model/tokenizer\")\n",
    "\n",
    "# # Releasing memory resources\n",
    "# del dpo_trainer, model\n",
    "# gc.collect()\n",
    "# torch.cuda.empty_cache()\n",
    "\n",
    "# # Loading the base model and tokenizer\n",
    "# base_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "#     peft_model_name,\n",
    "#     low_cpu_mem_usage=True,\n",
    "#     torch_dtype=torch.float16,\n",
    "#     return_dict=True\n",
    "# )\n",
    "# tokenizer = AutoTokenizer.from_pretrained(peft_model_name)\n",
    "\n",
    "# # Merging the base model with the adapter and unloading\n",
    "# model = PeftModel.from_pretrained(base_model, \"final_checkpoint\")\n",
    "# model = model.merge_and_unload()\n",
    "\n",
    "# # Saving the merged model and tokenizer\n",
    "# model.save_pretrained(new_model)\n",
    "# tokenizer.save_pretrained(new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
